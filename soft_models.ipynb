{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cc1beb-6259-4861-83f7-10f93e9cc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dffc0e6-699b-4101-9c2c-10c6e55288d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import product\n",
    "import scipy.stats as ss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as mtr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air.config import RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28396799-8820-4195-a7b6-549932d8f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b634b1ee-4311-4a5a-9737-97ce95bc9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/soft/gen/xgb_folds.pickle', 'rb') as handle:\n",
    "    cv_folds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb90834-fece-4ed4-9a69-f9b1c484c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = {key:df for key, df in cv_folds.items() if key != 0}\n",
    "train_df = pd.concat(train_folds, axis=0)\n",
    "X_train = train_df.drop('Dismissed', axis=1)\n",
    "y_train = train_df['Dismissed']\n",
    "test_df = cv_folds[0]\n",
    "X_test = test_df.drop('Dismissed', axis=1)\n",
    "y_test = test_df['Dismissed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dcbc7b-56a4-4f94-8ec8-d0e8237d3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:35] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[427   8]\n",
      " [ 17  84]]\n",
      "(0.9130434782608695, 0.8316831683168316, 0.8704663212435233)\n"
     ]
    }
   ],
   "source": [
    "def calc_metrics(preds, y_test):\n",
    "    cfm = mtr.confusion_matrix(y_test, preds)\n",
    "    prec = cfm[1][1] / (cfm[0][1] + cfm[1][1])\n",
    "    rec = cfm[1][1] / (cfm[1][0] + cfm[1][1])\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return prec, rec, f1\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(mtr.confusion_matrix(y_test, preds))\n",
    "print(calc_metrics(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956ffbba-cadd-436a-88a2-33f5341ee84f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance by model\n",
      "\n",
      "PaymentTypeId_9: 0.546999990940094\n",
      "\n",
      "PaymentTypeId_22: 0.0689999982714653\n",
      "\n",
      "LastLevelPeriod: 0.05700000002980232\n",
      "\n",
      "MonthOnSalary: 0.04100000113248825\n",
      "\n",
      "PosRate: 0.03099999949336052\n",
      "\n",
      "CompGeoNum: 0.03099999949336052\n",
      "\n",
      "WorkingPeriod: 0.026000000536441803\n",
      "\n",
      "APM: 0.024000000208616257\n",
      "\n",
      "Utilization: 0.023000000044703484\n",
      "\n",
      "ProjRateCompar: 0.020999999716877937\n",
      "\n",
      "PosRateCompar: 0.019999999552965164\n",
      "\n",
      "IntProjTime: 0.01899999938905239\n",
      "\n",
      "PosStrNum: 0.017000000923871994\n",
      "\n",
      "CustDismRate: 0.017000000923871994\n",
      "\n",
      "PosLevGeoNum: 0.013000000268220901\n",
      "\n",
      "ProjRate: 0.013000000268220901\n",
      "\n",
      "MeanHourVacation: 0.012000000104308128\n",
      "\n",
      "MonthsOnProject: 0.009999999776482582\n",
      "\n",
      "WageRate: 0.00800000037997961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "\n",
    "feature_importance = {}\n",
    "features = X_train.columns.tolist()\n",
    "for i, feature in enumerate(features):\n",
    "    feature_importance[feature] = round(importances[i], 3)\n",
    "\n",
    "feature_importance = dict(sorted(feature_importance.items(), key=lambda item: item[1], reverse=True))\n",
    "print(\"Feature importance by model\\n\")\n",
    "for key, val in feature_importance.items():\n",
    "    print(f'{key}: {val}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47825ac-1138-4e9c-a552-77628f29d291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_cv_metrics_imps(cv_folds):\n",
    "#     runs_metrics = []\n",
    "#     feat_importances = []\n",
    "#     feat_names = None\n",
    "#     for i in range(10):\n",
    "#         train_folds = {key:df for key, df in cv_folds.items() if key != i}\n",
    "#         train_df = pd.concat(train_folds, axis=0)\n",
    "#         X_train = train_df.drop('Dismissed', axis=1)\n",
    "#         y_train = train_df['Dismissed']\n",
    "#         test_df = cv_folds[i]\n",
    "#         X_test = test_df.drop('Dismissed', axis=1)\n",
    "#         y_test = test_df['Dismissed']\n",
    "        \n",
    "#         model = RandomForestClassifier()\n",
    "#         model.fit(X_train, y_train)\n",
    "#         preds = model.predict(X_test)\n",
    "        \n",
    "#         runs_metrics.append(calc_metrics(preds, y_test))\n",
    "        \n",
    "#         feat_names = X_train.columns.tolist()\n",
    "#         feat_importances.append(model.feature_importances_)\n",
    "#     runs_metrics = pd.DataFrame(runs_metrics, columns=['Prec', 'Rec', 'F1'])\n",
    "#     feat_importances = pd.DataFrame(feat_importances, columns=feat_names)\n",
    "#     return runs_metrics.mean(axis=0), feat_importances.mean(axis=0).sort_values(ascending=False)\n",
    "\n",
    "# path = './datasets/soft/gen/'\n",
    "# f_names = ['0m_cv_folds.pickle', '0m_lowcorr_cv_folds.pickle', '0m_lowcorr_imp_cv_folds.pickle']\n",
    "# for f_name in f_names:\n",
    "#     with open(f'{path}{f_name}', 'rb') as handle:\n",
    "#         cv_folds = pickle.load(handle)\n",
    "#     cv_metrics, imps = get_cv_metrics_imps(cv_folds)\n",
    "#     print(cv_metrics, '\\n')\n",
    "#     print(imps, '\\n**********************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a821ad3-8e26-4aae-92f6-d48aaccf837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iqr_values_mask(col):\n",
    "    Q1 = col.quantile(0.25)\n",
    "    Q3 = col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    filter_mask = (col >= Q1 - 1.5 * IQR) & (col <= Q3 + 1.5 *IQR)\n",
    "    return filter_mask\n",
    "\n",
    "def get_metrics_mean(cv_metrics):\n",
    "    mask = get_iqr_values_mask(cv_metrics['Prec']) & get_iqr_values_mask(cv_metrics['Rec'])\n",
    "    # print(mask)\n",
    "    filt_metrics = cv_metrics[mask]\n",
    "    return filt_metrics.mean()\n",
    "\n",
    "def calc_metrics(preds, y_test):\n",
    "    cfm = mtr.confusion_matrix(y_test, preds)\n",
    "    prec = cfm[1][1] / (cfm[0][1] + cfm[1][1])\n",
    "    rec = cfm[1][1] / (cfm[1][0] + cfm[1][1])\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return prec, rec, f1\n",
    "\n",
    "def get_cv_metrics(cv_folds, model_cls, model_hps={}):\n",
    "    runs_metrics = []\n",
    "    for i in range(10):\n",
    "        train_folds = {key:df for key, df in cv_folds.items() if key != i}\n",
    "        train_df = pd.concat(train_folds, axis=0)\n",
    "        X_train = train_df.drop('Dismissed', axis=1)\n",
    "        y_train = train_df['Dismissed']\n",
    "        test_df = cv_folds[i]\n",
    "        X_test = test_df.drop('Dismissed', axis=1)\n",
    "        y_test = test_df['Dismissed']\n",
    "        \n",
    "        model = model_cls(**model_hps)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        runs_metrics.append(calc_metrics(preds, y_test))\n",
    "    runs_metrics = pd.DataFrame(runs_metrics, columns=['Prec', 'Rec', 'F1'])\n",
    "    return runs_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef83ab6-f3a3-48a7-b155-aac83914f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics std < 0.05:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prec    True\n",
       "Rec     True\n",
       "F1      True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered means:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prec    0.741459\n",
       "Rec     0.754767\n",
       "F1      0.747872\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "Metrics std < 0.05:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prec    True\n",
       "Rec     True\n",
       "F1      True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered means:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prec    0.934359\n",
       "Rec     0.737074\n",
       "F1      0.823749\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "Metrics std < 0.05:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prec    True\n",
       "Rec     True\n",
       "F1      True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered means:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prec    0.923203\n",
       "Rec     0.825195\n",
       "F1      0.871316\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n"
     ]
    }
   ],
   "source": [
    "path = './datasets/soft/gen/'\n",
    "f_name = 'xgb_folds.pickle'\n",
    "\n",
    "models_info = [(DecisionTreeClassifier, {}),\n",
    "               (RandomForestClassifier, {}),\n",
    "               (XGBClassifier, {'use_label_encoder': False,\n",
    "                               'verbosity': 0,\n",
    "                               'random_state': 10})\n",
    "               # (svm.SVC, {'kernel': 'linear'}),\n",
    "               # (svm.SVC, {'kernel': 'rbf'}),\n",
    "               # (svm.SVC, {'kernel': 'poly'}),\n",
    "               ]\n",
    "\n",
    "with open(f'{path}{f_name}', 'rb') as handle:\n",
    "    cv_folds = pickle.load(handle)\n",
    "for cl, hps in models_info:\n",
    "    cv_metrics = get_cv_metrics(cv_folds, cl, hps)\n",
    "    print(\"Metrics std < 0.05:\")\n",
    "    display(cv_metrics.std(axis=0) < 0.05)\n",
    "    metrics_means = get_metrics_mean(cv_metrics)\n",
    "    print('Filtered means:')\n",
    "    display(metrics_means)\n",
    "    print('**********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1b0e75-6979-407c-a28d-9a66051c21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_results(cv_folds, model):\n",
    "    runs_metrics = []\n",
    "    for i in range(10):\n",
    "        train_folds = {key:df for key, df in cv_folds.items() if key != i}\n",
    "        train_df = pd.concat(train_folds, axis=0)\n",
    "        X_train = train_df.drop('Dismissed', axis=1)\n",
    "        y_train = train_df['Dismissed']\n",
    "        test_df = cv_folds[i]\n",
    "        X_test = test_df.drop('Dismissed', axis=1)\n",
    "        y_test = test_df['Dismissed']\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        runs_metrics.append(calc_metrics(preds, y_test))\n",
    "    runs_metrics = pd.DataFrame(runs_metrics, columns=['Prec', 'Rec', 'F1'])\n",
    "    \n",
    "    return runs_metrics\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\": tune.loguniform(100, 10000),\n",
    "    \"max_depth\": tune.randint(0, 5),\n",
    "    \"subsample\": tune.quniform(0.25, 0.75, 0.01),\n",
    "    \"colsample_bytree\": tune.quniform(0.05, 0.5, 0.01),\n",
    "    \"colsample_bylevel\": tune.quniform(0.05, 0.5, 0.01),    \n",
    "    \"learning_rate\": tune.quniform(-3.0, -1.0, 0.5) # pows of 10\n",
    "}\n",
    "\n",
    "params = [k for k in search_space.keys() if k != 'wandb']\n",
    "\n",
    "def objective(config):\n",
    "    config['n_estimators'] = int(config['n_estimators'])\n",
    "    config['max_depth'] = int(config['max_depth']) + 2\n",
    "    config['learning_rate'] = 10 ** config['learning_rate']\n",
    "    \n",
    "    xgb = XGBClassifier(\n",
    "        random_state=RANDOMSTATE,\n",
    "        booster='gbtree',\n",
    "        scale_pos_weight=1,\n",
    "        use_label_encoder=False,\n",
    "        **config\n",
    "    )\n",
    "    cv_metrics = get_cv_results(cv_folds, xgb)\n",
    "    metrics_means = get_metrics_mean(cv_metrics)\n",
    "    rec = metrics_means['Rec']\n",
    "    \n",
    "    return {\"rec\": rec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f923d3-b4e6-42a8-9844-0dca2996e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-09-06 11:57:44 (running for 00:31:05.85)<br>Memory usage on this node: 6.0/7.2 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: 0.4725545471213788<br>Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.76 GiB heap, 0.0/0.88 GiB objects<br>Current best trial: a1877352 with rec=0.4725545471213788 and parameters={'n_estimators': 171, 'max_depth': 2, 'subsample': 0.53, 'colsample_bytree': 0.36, 'colsample_bylevel': 0.07, 'learning_rate': 0.03162277660168379}<br>Result logdir: /home/vivi/tune_results/hyperopt_xgb<br>Number of trials: 8/10 (1 PENDING, 6 RUNNING, 1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(pid=12812)\u001b[0m   from pandas import MultiIndex, Int64Index\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:26:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(pid=12844)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(pid=12844)\u001b[0m   from pandas import MultiIndex, Int64Index\n",
      "\u001b[2m\u001b[36m(pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(pid=12853)\u001b[0m   from pandas import MultiIndex, Int64Index\n",
      "\u001b[2m\u001b[36m(pid=12850)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(pid=12850)\u001b[0m   from pandas import MultiIndex, Int64Index\n",
      "\u001b[2m\u001b[36m(pid=12847)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(pid=12847)\u001b[0m   from pandas import MultiIndex, Int64Index\n",
      "\u001b[2m\u001b[36m(pid=12849)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(pid=12849)\u001b[0m   from pandas import MultiIndex, Int64Index\n",
      "\u001b[2m\u001b[36m(objective pid=12850)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12850)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12844)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12844)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12849)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12849)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:26:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12847)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12847)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12844)\u001b[0m [11:26:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12850)\u001b[0m [11:26:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12849)\u001b[0m [11:26:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12847)\u001b[0m [11:26:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:27:57] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:29:07] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:30:15] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:30:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:31:28] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:32:41] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:33:55] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:34:44] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:35:07] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:36:20] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:37:32] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:38:34] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:38:50] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:43:01] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:43:47] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12849)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12849)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12849)\u001b[0m [11:43:54] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:47:12] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:48:55] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:51:23] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12853)\u001b[0m [11:54:28] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m /home/vivi/PycharmProjects/internship/nenv/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "\u001b[2m\u001b[36m(objective pid=12812)\u001b[0m [11:57:02] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-09-06 11:57:43,288\tWARNING tune.py:686 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "*** SIGTERM received at time=1662454665 on cpu 2 ***\n",
      "PC: @     0x7f6fbd3b5197  (unknown)  (unknown)\n",
      "    @     0x7f6fbd366520  (unknown)  (unknown)\n",
      "    @ ... and at least 1 more frames\n",
      "[2022-09-06 11:57:45,419 E 12498 12498] logging.cc:361: *** SIGTERM received at time=1662454665 on cpu 2 ***\n",
      "[2022-09-06 11:57:45,419 E 12498 12498] logging.cc:361: PC: @     0x7f6fbd3b5197  (unknown)  (unknown)\n",
      "[2022-09-06 11:57:45,419 E 12498 12498] logging.cc:361:     @     0x7f6fbd366520  (unknown)  (unknown)\n",
      "[2022-09-06 11:57:45,419 E 12498 12498] logging.cc:361:     @ ... and at least 1 more frames\n"
     ]
    }
   ],
   "source": [
    "RANDOMSTATE = 10\n",
    "NUM_SAMPLES = 10\n",
    "\n",
    "algo = HyperOptSearch(random_state_seed=RANDOMSTATE)\n",
    "\n",
    "scheduler = ASHAScheduler()\n",
    "\n",
    "tuner = tune.Tuner(objective,\n",
    "               param_space=search_space,\n",
    "               tune_config=tune.TuneConfig(\n",
    "                    num_samples=NUM_SAMPLES,\n",
    "                    search_alg=algo,\n",
    "                    scheduler=scheduler,\n",
    "                    metric=\"rec\",\n",
    "                    mode=\"max\"\n",
    "               ),\n",
    "                run_config=RunConfig(\n",
    "                    verbose=1,\n",
    "                    name=\"hyperopt_xgb\",\n",
    "                    local_dir=\"~/tune_results\"\n",
    "                ))\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35824a5f-b898-42bb-8a3b-6b6f7c1865f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.get_best_result(metric=\"rec\", mode=\"max\").config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13dac8-02f0-42d4-b64b-064c193305c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path = './datasets/soft/gen/'\n",
    "# f_names = ['xgb_folds.pickle']\n",
    "# models_info = [(RandomForestClassifier, {}),\n",
    "#                (XGBClassifier, {'use_label_encoder': False})]\n",
    "#                # (svm.SVC, {'kernel': 'linear'}),\n",
    "#                # (svm.SVC, {'kernel': 'rbf'}),\n",
    "#                # (svm.SVC, {'kernel': 'poly'}),\n",
    "#                # (DecisionTreeClassifier, {})]\n",
    "# for f_name in f_names:\n",
    "#     with open(f'{path}{f_name}', 'rb') as handle:\n",
    "#         cv_folds = pickle.load(handle)\n",
    "#     for cl, hps in models_info[1:]:\n",
    "#         cv_metrics = get_cv_metrics(cv_folds, cl, hps)\n",
    "#         print(cv_metrics,\n",
    "#               '\\n**********************************')\n",
    "#     print('----------------------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
